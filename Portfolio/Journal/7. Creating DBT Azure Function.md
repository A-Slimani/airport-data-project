Since completing part of the pipeline I have to create an Azure function for dbt to run in the pipeline. Dbt is generally ran through the CLI however there is a library of which I can use to run dbt through python. I also have to make modifications so that I point to the correct project and profile since I am running this outside of the dbt directory.

```python
dbt = dbtRunner() 
res = dbt.invoke([
    "run",
    "--project-dir", "./airportdbt",
    "--profiles-dir", "./airportdbt"
])
```

## Running dbt seed through AZ function

When trying to add dbt I have encountered an issue when running the dbt command it does not provide the correct output on success. I currently get this output on a successful run

```log
dbtRunnerResult(success=False, exception=TypeError("MessageToJson() got an unexpected keyword argument 'always_print_fields_with_no_presence'"), result=None)
```

Unfortunately fixing this would require me to downgrade `dbt-core` which would mean I have to change my tests since they are not compatible in the old version. I also tried to replace using `dbtRunner` to `subprocess` however I also face the same issue there. A bit unsure where to go from here, however I believe logging and checking success of pipeline runs are important for tracking so the idea of downgrading seemed like the choice to make however the latest supported version of `dbt-core` is version 1.10 which is still using protobuf version higher than what a I want (5.x) vs (4.x). I think I will write a workaround for this that will just return SUCCESS and log the response as well. I will keep an eye on this to see if it fails to capture errors and what I could do to fix it. 

Issue was actually I was using an older version of protobuf that wasn't compatible with current dbt. Tried to fix it from defaulting to the new protobuf with this `"PYTHON_ISOLATE_WORKER_DEPENDENCIES": "1"`. This will default to using my libraries instead of azure functions default libraries Changing this only added new layers of issues. Decided to try using a docker container inside azure and add that to the pipeline however looking at the container options it seems like if I were to create my own docker image I would have to pay around 17 cents a day which is too much in this economy. I will just try to write a manual workaround for this issue.




